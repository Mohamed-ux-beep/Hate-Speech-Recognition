{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohamed-ux-beep/Hate-Speech-Recognition/blob/main/hate_speech_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_KVigRN7NqLE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import RobertaModel, RobertaTokenizer, RobertaConfig\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufpX4DMFrdYr",
        "outputId": "9ad21776-abed-492a-8bde-d0b3367e9a1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing-extensions==3.10.0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDU2VlmfOT97",
        "outputId": "a3ecc87a-3673-4030-abaa-1b4b781afa02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions==3.10.0.2\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "sqlalchemy 2.0.23 requires typing-extensions>=4.2.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "arviz 0.15.1 requires typing-extensions>=4.1.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "chex 0.1.7 requires typing-extensions>=4.2.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "fastapi 0.108.0 requires typing-extensions>=4.8.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "flax 0.7.5 requires typing-extensions>=4.2, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "gradio 4.13.0 requires typing-extensions~=4.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "gradio-client 0.8.0 requires typing-extensions~=4.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "ibis-framework 6.2.0 requires typing-extensions<5,>=4.3.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "librosa 0.10.1 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "polars 0.17.3 requires typing_extensions>=4.0.1; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "pydantic 2.5.3 requires typing-extensions>=4.6.1, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "pydantic-core 2.14.6 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "python-utils 3.8.1 requires typing-extensions>3.10.0.2, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "uvicorn 0.25.0 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-3.10.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTLMotCWNnA1",
        "outputId": "62b90a88-89ae-4784-a826-01e57a188aec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "J7klfvqaOlL7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9AZUC5qXBc6W"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/cleaned_data.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "5tx39Rl8BiWX",
        "outputId": "a505a91d-eeb5-4129-f693-fc877255bd57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   tweet  class\n",
              "index                                                          \n",
              "0      cnn call wall school buld mchgan chant tcot mddle      1\n",
              "1      comment opkllngbay seashepherd australa helpco...      1\n",
              "2                                          agree retweet      1\n",
              "3                                        prove say lumpy      1\n",
              "4      unbelevable neverump somethng st need xenophob...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23d800e1-963d-4f80-bc96-8c20661d4c74\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnn call wall school buld mchgan chant tcot mddle</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>comment opkllngbay seashepherd australa helpco...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>agree retweet</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>prove say lumpy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>unbelevable neverump somethng st need xenophob...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23d800e1-963d-4f80-bc96-8c20661d4c74')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23d800e1-963d-4f80-bc96-8c20661d4c74 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23d800e1-963d-4f80-bc96-8c20661d4c74');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94ec53e7-4f26-49ed-92c2-4cb5c4958e4a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94ec53e7-4f26-49ed-92c2-4cb5c4958e4a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94ec53e7-4f26-49ed-92c2-4cb5c4958e4a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XmVxHVGwOF9A"
      },
      "outputs": [],
      "source": [
        "# check point of the model\n",
        "check_point = 'roberta-base'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "707a3ykEONq-"
      },
      "outputs": [],
      "source": [
        "# configuration : dictionary of parameters\n",
        "config = {\n",
        "    'max_len': 140,\n",
        "    'train_batch_size': 16, #16\n",
        "    'valid_batch_size': 8,\n",
        "    'learning rate': 1e-5,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7icTBTtORvq",
        "outputId": "6a445f37-8297-4cb7-ad4e-75cfb063034b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# tokenizer defining\n",
        "tokenizer = RobertaTokenizer.from_pretrained(check_point, truncation=True, do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iFP1ec9dOV4v"
      },
      "outputs": [],
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.tweet = dataframe['tweet']\n",
        "        self.labels = dataframe['class']\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.tweet[item])\n",
        "        text = \" \".join(text.split())\n",
        "        inputs = self.tokenizer.encode_plus(text,None, add_special_tokens=True, max_length=self.max_len, padding='max_length', return_token_type_ids=True)\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "\n",
        "        # convert to tensors\n",
        "        return {\n",
        "            'ids': torch.tensor(ids,dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'labels': torch.tensor(self.labels[item], dtype=torch.int64)}\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Se0UjiGMOWqy"
      },
      "outputs": [],
      "source": [
        "# data splitting using train_test_split from Scikit learn with shuffle True\n",
        "def split_data(dataframe):\n",
        "    \"\"\" The train and validation data will be together and called X_train, the test will be called X_test\"\"\"\n",
        "    d_train, d_test = train_test_split(dataframe, test_size=0.3, shuffle=True, random_state=42)\n",
        "\n",
        "    \"\"\"Splitting the train data to train & validation data\"\"\"\n",
        "    d_train, d_valid = train_test_split(d_train, test_size=0.2)\n",
        "\n",
        "    # reindexing each df\n",
        "    d_train.reset_index(inplace=True)\n",
        "    d_valid.reset_index(inplace=True)\n",
        "    d_test.reset_index(inplace=True)\n",
        "    del d_train['index'], d_valid['index'], d_test['index']\n",
        "\n",
        "    print('The Splitting is done sucessfully with:\\n')\n",
        "    print(f'1. {round(len(d_train)/len(dataframe) * 100, 2)} % Training data,')\n",
        "    print(f'2. {round(len(d_valid)/len(dataframe) * 100, 2)} % Validation data and')\n",
        "    print(f'3. {round(len(d_test)/len(dataframe) * 100, 2)} % test data ..')\n",
        "    return d_train, d_valid, d_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dXP57qHOOb0c"
      },
      "outputs": [],
      "source": [
        "def train_valid_set(train_data, valid_data, tokenizer, max_len):\n",
        "    train_dataset = Data(train_data, tokenizer, config['max_len'])\n",
        "    valid_dataset = Data(valid_data, tokenizer, config['max_len'])\n",
        "    print('Training and Validation datasets are ready for DataLoaders ..')\n",
        "    return train_dataset, valid_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UEAEZJVVOds2"
      },
      "outputs": [],
      "source": [
        "# Preparation of dataloaders\n",
        "train_params = {\n",
        "    'batch_size': config['train_batch_size'],\n",
        "    'shuffle': True,\n",
        "    'num_workers': 0\n",
        "}\n",
        "valid_params = {\n",
        "    'batch_size': config['valid_batch_size'],\n",
        "    'shuffle': True,\n",
        "    'num_workers': 0\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NCcinu9qOfq0"
      },
      "outputs": [],
      "source": [
        "def data_loadrs(train_dataset, valid_dataset, train_params, valid_params):\n",
        "    training_loader = DataLoader(train_dataset, **train_params)\n",
        "    valid_loader = DataLoader(valid_dataset, **valid_params)\n",
        "    print('Training and Validation dataloaders are ready ..')\n",
        "    return training_loader, valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "tgG8A4F2Oh9v"
      },
      "outputs": [],
      "source": [
        "class Roberta(torch.nn.Module): #torch.nn.Module\n",
        "    def __init__(self, check_point):\n",
        "        self.check_point = check_point\n",
        "        super(Roberta, self).__init__()\n",
        "        self.layer1 = RobertaModel.from_pretrained(self.check_point)\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768) # in features and out features\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 2)\n",
        "        self.result = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    # feed forward\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output = self.layer1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        hidden_state = output[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output_ = self.classifier(pooler)\n",
        "        result = self.result(output_)\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFD-m4xn2995",
        "outputId": "a0775512-8730-4922-ee61-dd0673f7f1cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "#del variable\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyRnGwGeOkKF"
      },
      "outputs": [],
      "source": [
        "# defining the device and model which will be fine tuned for classification\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = Roberta(check_point)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "l9otXCg-OmQu"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(preds, targets):\n",
        "    n_correct = (preds == targets).sum().item()\n",
        "    return n_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WWKTk_HhOoFX"
      },
      "outputs": [],
      "source": [
        "def define_loss_optimizer():\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=config['learning rate'])\n",
        "    print(' criterion and optimizer are ready , we can start training ..')\n",
        "    return criterion, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kr0Zf55aOsIL"
      },
      "outputs": [],
      "source": [
        "# training & validating the model\n",
        "def train_model(model, training_loader,loss_func, optimizer, epochs):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    # putting the model on training mode\n",
        "    model.train()\n",
        "    for _, data in tqdm(enumerate(training_loader, 0)):\n",
        "        ids = data['ids'].to(device, dtype=torch.long)\n",
        "        mask = data['mask'].to(device, dtype=torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "        labels = data['labels'].to(device, dtype=torch.float) #should be changed\n",
        "\n",
        "        # pass to the model\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        labels = labels.to(torch.int64)\n",
        "        loss = loss_func(outputs, labels) # source of the error\n",
        "        tr_loss += loss.item()\n",
        "        max_tok, max_idx = torch.max(outputs.data, dim=1)\n",
        "        n_correct += calculate_accuracy(max_idx, labels)\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += labels.size(0)\n",
        "\n",
        "        if _ % 5000 == 0:\n",
        "            loss_step = tr_loss / nb_tr_steps\n",
        "            acc_step = (n_correct * 100) / nb_tr_examples\n",
        "            acc_step = round(acc_step, 2)\n",
        "            print(f\"\\n\\n Training loss and accuracy per 5000 steps is {loss_step} and {acc_step} % \\n\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    epoch_acc = (n_correct * 100)/ nb_tr_examples\n",
        "    epoch_acc = round(epoch_acc, 2)\n",
        "    print(f\"\\n Total Training loss and accuracy for Epoch {epochs}: {epoch_loss} and {epoch_acc} % \\n\")\n",
        "    return labels, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0WSFL9fnOtl7"
      },
      "outputs": [],
      "source": [
        "def valid_model(model, valid_loader, loss_func, epochs):\n",
        "    val_loss = 0\n",
        "    n_correct, n_wrong = 0, 0\n",
        "    nb_val_steps, nb_val_examples = 0, 0\n",
        "    preds_list = []\n",
        "    label_list = []\n",
        "\n",
        "    # put the model on validation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for _, data in tqdm(enumerate(valid_loader, 0)):\n",
        "            # get the inputs of the model\n",
        "            ids = data['ids'].to(device, dtype=torch.long)\n",
        "            mask = data['mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            labels = data['labels'].to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            labels = labels.to(torch.int64)\n",
        "            loss = loss_func(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            max_tok, max_idx = torch.max(outputs.data, dim=1)\n",
        "            n_correct += calculate_accuracy(max_idx, labels)\n",
        "\n",
        "            nb_val_steps += 1\n",
        "            nb_val_examples += labels.size(0)\n",
        "            preds_list.append(outputs.cpu().detach().numpy())\n",
        "            label_list.append(max_idx.cpu().detach().numpy())\n",
        "\n",
        "            if _ % 5000 == 0:\n",
        "                loss_step = val_loss / nb_val_steps\n",
        "                acc_step = (n_correct * 100) / nb_val_examples\n",
        "                acc_step = round(acc_step, 2)\n",
        "                print(f\"\\n\\n Validation loss and accuracy per 5000 steps is {loss_step} and {acc_step} % \\n\")\n",
        "\n",
        "    epoch_loss = val_loss / nb_val_steps\n",
        "    epoch_acc = (n_correct * 100) / nb_val_examples\n",
        "    epoch_acc = round(epoch_acc, 2)\n",
        "    print(f\"\\n Total Validation loss and accuracy for Epoch {epochs}: {epoch_loss} and {epoch_acc} % \\n\")\n",
        "    return label_list, preds_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kErs5EJeO29a"
      },
      "outputs": [],
      "source": [
        "def Go(model, training_loader, valid_loader, loss_func, optimizer, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch number: {epoch+1}\\n\")\n",
        "        tr_labels, tr_preds = train_model(model, training_loader, loss_func, optimizer, epoch+1)\n",
        "        val_label, val_pred = valid_model(model, valid_loader, loss_func, epoch+1)\n",
        "        print('= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =')\n",
        "    return tr_labels, tr_preds, val_label, val_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABjkwtZfIGLb"
      },
      "source": [
        "**first step**<br>\n",
        "\n",
        "Splitting of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JpaaA3DILhH",
        "outputId": "7a5ff7d8-addd-4a40-93ca-4d717dc5fa2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Splitting is done sucessfully with:\n",
            "\n",
            "1. 56.0 % Training data,\n",
            "2. 14.0 % Validation data and\n",
            "3. 30.0 % test data ..\n"
          ]
        }
      ],
      "source": [
        "d_train, d_valid, d_test = split_data(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gRgyLOILMr8"
      },
      "source": [
        "**Datasets**<br>\n",
        "\n",
        "getting the dataset for training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoMqQA67LTkn",
        "outputId": "47a2e972-2bee-48f8-d156-9dc10a093146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Validation datasets are ready for DataLoaders ..\n"
          ]
        }
      ],
      "source": [
        "tr_dataset, v_dataset = train_valid_set(d_train, d_valid, tokenizer, config['max_len'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yoz2c1hpLtSJ"
      },
      "source": [
        "**Dataloaders** <br>\n",
        "\n",
        "getting the dataloaders for training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXU6_aGmL0WS",
        "outputId": "15818770-5ad6-436b-c382-ceaa6a2cab7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Validation dataloaders are ready ..\n"
          ]
        }
      ],
      "source": [
        "tr_dataloader, v_dataloader = data_loadrs(tr_dataset, v_dataset, train_params, valid_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETbevLtuMU_x"
      },
      "source": [
        "**Loss function and optimizer**<br>\n",
        "\n",
        "Defining of loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "b9GUUoIPMb7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7089ac-eb76-4406-ed31-5eb3576ae19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " criterion and optimizer are ready , we can start training ..\n"
          ]
        }
      ],
      "source": [
        "criterion, optimizer = define_loss_optimizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tuIBepmMo48"
      },
      "source": [
        "**Training and validation of the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FM-lcd9NobX",
        "outputId": "4bf17f0c-5693-4280-9720-82251741b787"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch number: 1\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Training loss and accuracy per 5000 steps is 0.6983146071434021 and 56.25 % \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1691it [11:37,  2.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Total Training loss and accuracy for Epoch 1: 0.4224656824703262 and 88.65 % \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3it [00:00,  8.93it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Validation loss and accuracy per 5000 steps is 0.38280922174453735 and 87.5 % \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "846it [01:00, 13.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Total Validation loss and accuracy for Epoch 1: 0.38532989068797857 and 92.41 % \n",
            "\n",
            "= = = = = = =  = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
            "Epoch number: 2\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:00,  5.64it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Training loss and accuracy per 5000 steps is 0.3138818144798279 and 100.0 % \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1691it [11:41,  2.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Total Training loss and accuracy for Epoch 2: 0.3830400156171134 and 92.76 % \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3it [00:00,  8.94it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Validation loss and accuracy per 5000 steps is 0.36337026953697205 and 87.5 % \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "846it [01:00, 13.95it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Total Validation loss and accuracy for Epoch 2: 0.3986502310203886 and 90.73 % \n",
            "\n",
            "= = = = = = =  = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
            "Epoch number: 3\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:00,  5.37it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Training loss and accuracy per 5000 steps is 0.4781329333782196 and 81.25 % \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1691it [11:41,  2.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Total Training loss and accuracy for Epoch 3: 0.3735562845280296 and 93.8 % \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3it [00:00,  8.92it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Validation loss and accuracy per 5000 steps is 0.43824243545532227 and 87.5 % \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "846it [01:00, 13.91it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Total Validation loss and accuracy for Epoch 3: 0.38706021708376864 and 92.47 % \n",
            "\n",
            "= = = = = = =  = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
            "Epoch number: 4\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:00,  5.84it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Training loss and accuracy per 5000 steps is 0.3757752478122711 and 93.75 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1691it [11:40,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total Training loss and accuracy for Epoch 4: 0.3700697580115602 and 94.2 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3it [00:00,  8.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Validation loss and accuracy per 5000 steps is 0.31327006220817566 and 100.0 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "846it [01:00, 13.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total Validation loss and accuracy for Epoch 4: 0.37140823238425785 and 94.09 % \n",
            "\n",
            "= = = = = = =  = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tr_labels, tr_preds, val_label, val_pred = Go(model, tr_dataloader, v_dataloader, criterion, optimizer, 4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to a file\n",
        "torch.save(model.state_dict(), 'hate_speech_recognition_model.pth')"
      ],
      "metadata": {
        "id": "ICkchk81n0EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loaded_model\n",
        "#torch.load_state_dict(torch.load('model.pth'))\n",
        "\n",
        "# Put the model in evaluation mode (if needed)\n",
        "#loaded_model.eval()"
      ],
      "metadata": {
        "id": "mSsMZTXIn9i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence, tokenizer, max_len):\n",
        "    text = \" \".join(sentence.split())\n",
        "    inputs = tokenizer.encode_plus(text, None, add_special_tokens=True, max_length=max_len, padding='max_length', return_token_type_ids=True)\n",
        "    ids = inputs['input_ids']\n",
        "    mask = inputs['attention_mask']\n",
        "    token_type_ids = inputs['token_type_ids']\n",
        "\n",
        "    # convert to tensors\n",
        "    return {\n",
        "        'ids': torch.tensor(ids, dtype=torch.long),\n",
        "        'mask': torch.tensor(mask, dtype=torch.long),\n",
        "        'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "DHcB1tqcohns"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        inputs = preprocess_sentence(sentence, tokenizer, config['max_len'])\n",
        "        ids = inputs['ids'].to(device, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
        "        mask = inputs['mask'].to(device, dtype=torch.long).unsqueeze(0)\n",
        "        token_type_ids = inputs['token_type_ids'].to(device, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        _, predicted_class = torch.max(outputs.data, dim=1)\n",
        "        prediction_ = predicted_class.item()\n",
        "        id2label = {0: 'Not Hate Speech', 1: 'Hate Speech'}\n",
        "        result = id2label[prediction_]\n",
        "        return   result  # Return the predicted class index"
      ],
      "metadata": {
        "id": "kuu9n4Vxopov"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence = \"u are hero\"\n",
        "prediction3 = predict(new_sentence)"
      ],
      "metadata": {
        "id": "jdRAFy_eori7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kPgjH3I4o0rQ",
        "outputId": "fd28129c-495c-49b6-c828-44d57d13420a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Not Hate Speech'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = gr.Textbox(label=\"Enter Tweet:\")\n",
        "output_label = gr.Label(label=\"Prediction:\")\n",
        "\n",
        "prediction = gr.Interface(fn=predict,\n",
        "                          inputs=input_text,\n",
        "                          outputs=output_label,\n",
        "                          title='Hate Speech Recognition',\n",
        "                          description='Classify This Tweet!')\n",
        "\n",
        "# Run the interface\n",
        "prediction.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "McZl4_VtPQuJ",
        "outputId": "faddf6e1-4c7b-4c76-bc63-265584f7e9ff"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ed5fb8c9168f8ad05b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ed5fb8c9168f8ad05b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNO+uIEnlzxkP3ZBcbPGQzz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}